{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 19727,
     "status": "ok",
     "timestamp": 1750087938575,
     "user": {
      "displayName": "Jo LImonadnui",
      "userId": "13339600552952595370"
     },
     "user_tz": -180
    },
    "id": "eaLeJGvwm0Ia"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models.vgg import vgg16\n",
    "\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision.transforms import Compose, RandomCrop, ToTensor, ToPILImage, CenterCrop, Resize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1750087938610,
     "user": {
      "displayName": "Jo LImonadnui",
      "userId": "13339600552952595370"
     },
     "user_tz": -180
    },
    "id": "QIO8P3Em2Crd"
   },
   "outputs": [],
   "source": [
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])\n",
    "\n",
    "def calculate_valid_crop_size(crop_size, upscale_factor):\n",
    "    return crop_size - (crop_size % upscale_factor)\n",
    "\n",
    "def train_hr_transform(crop_size):\n",
    "    return Compose([\n",
    "        RandomCrop(crop_size),\n",
    "        ToTensor(),\n",
    "    ])\n",
    "\n",
    "def train_lr_transform(crop_size, upscale_factor):\n",
    "    return Compose([\n",
    "        ToPILImage(),\n",
    "        Resize(crop_size // upscale_factor, interpolation=Image.BICUBIC),\n",
    "        ToTensor()\n",
    "    ])\n",
    "\n",
    "def display_transform():\n",
    "    return Compose([\n",
    "        ToPILImage(),\n",
    "        Resize(400),\n",
    "        CenterCrop(400),\n",
    "        ToTensor()\n",
    "    ])\n",
    "\n",
    "class TrainDatasetFromFolder(Dataset):\n",
    "    def __init__(self, dataset_dir, crop_size, upscale_factor=2):\n",
    "        super(TrainDatasetFromFolder, self).__init__()\n",
    "        self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\n",
    "        crop_size = calculate_valid_crop_size(crop_size, upscale_factor)\n",
    "        self.hr_transform = train_hr_transform(crop_size)\n",
    "        self.lr_transform = train_lr_transform(crop_size, upscale_factor)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        hr_image = self.hr_transform(Image.open(self.image_filenames[index]))\n",
    "        lr_image = self.lr_transform(hr_image)\n",
    "        return lr_image, hr_image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "\n",
    "class ValDatasetFromFolder(Dataset):\n",
    "    def __init__(self, dataset_dir, crop_size, upscale_factor=2):\n",
    "        super(ValDatasetFromFolder, self).__init__()\n",
    "        self.upscale_factor = upscale_factor\n",
    "        self.crop_size = crop_size\n",
    "        self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        hr_image = Image.open(self.image_filenames[index])\n",
    "        w, h = hr_image.size\n",
    "        self.crop_size = calculate_valid_crop_size(min(w, h), self.upscale_factor)\n",
    "        lr_scale = Resize(self.crop_size // self.upscale_factor, interpolation=Image.BICUBIC)\n",
    "        hr_scale = Resize(self.crop_size, interpolation=Image.BICUBIC)\n",
    "        hr_image = CenterCrop(crop_size)(hr_image)\n",
    "        lr_image = lr_scale(hr_image)\n",
    "        hr_restore_img = hr_scale(lr_image)\n",
    "        return ToTensor()(lr_image), ToTensor()(hr_restore_img), ToTensor()(hr_image)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "\n",
    "class TestDatasetFromFolder(Dataset):\n",
    "    def __init__(self, dataset_dir, upscale_factor=2):\n",
    "        super(TestDatasetFromFolder, self).__init__()\n",
    "        self.lr_path = dataset_dir + '/SRF_' + str(upscale_factor) + '/data/'\n",
    "        self.hr_path = dataset_dir + '/SRF_' + str(upscale_factor) + '/target/'\n",
    "        self.upscale_factor = upscale_factor\n",
    "        self.lr_filenames = [join(self.lr_path, x) for x in listdir(self.lr_path) if is_image_file(x)]\n",
    "        self.hr_filenames = [join(self.hr_path, x) for x in listdir(self.hr_path) if is_image_file(x)]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.lr_filenames[index].split('/')[-1]\n",
    "        lr_image = Image.open(self.lr_filenames[index])\n",
    "        w, h = lr_image.size\n",
    "        hr_image = Image.open(self.hr_filenames[index])\n",
    "        hr_scale = Resize((self.upscale_factor * h, self.upscale_factor * w), interpolation=Image.BICUBIC)\n",
    "        hr_restore_img = hr_scale(lr_image)\n",
    "        return image_name, ToTensor()(lr_image), ToTensor()(hr_restore_img), ToTensor()(hr_image)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lr_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1750087938640,
     "user": {
      "displayName": "Jo LImonadnui",
      "userId": "13339600552952595370"
     },
     "user_tz": -180
    },
    "id": "2tPb-hYj36Cs"
   },
   "outputs": [],
   "source": [
    "class GeneratorLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorLoss, self).__init__()\n",
    "        vgg = vgg16(pretrained=True)\n",
    "        loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\n",
    "        for param in loss_network.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.loss_network = loss_network\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.tv_loss = TVLoss()\n",
    "\n",
    "    def forward(self, out_labels, out_images, target_images):\n",
    "        adversarial_loss = torch.mean(1 - out_labels)\n",
    "        perception_loss = self.mse_loss(self.loss_network(out_images), self.loss_network(target_images))\n",
    "        image_loss = self.mse_loss(out_images, target_images)\n",
    "        tv_loss = self.tv_loss(out_images)\n",
    "        return image_loss + 0.001 * adversarial_loss + 0.006 * perception_loss + 2e-8 * tv_loss\n",
    "\n",
    "\n",
    "class TVLoss(nn.Module):\n",
    "    def __init__(self, tv_loss_weight=1):\n",
    "        super(TVLoss, self).__init__()\n",
    "        self.tv_loss_weight = tv_loss_weight\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size()[0]\n",
    "        h_x = x.size()[2]\n",
    "        w_x = x.size()[3]\n",
    "        count_h = self.tensor_size(x[:, :, 1:, :])\n",
    "        count_w = self.tensor_size(x[:, :, :, 1:])\n",
    "        h_tv = torch.pow((x[:, :, 1:, :] - x[:, :, :h_x - 1, :]), 2).sum()\n",
    "        w_tv = torch.pow((x[:, :, :, 1:] - x[:, :, :, :w_x - 1]), 2).sum()\n",
    "        return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n",
    "\n",
    "    @staticmethod\n",
    "    def tensor_size(t):\n",
    "        return t.size()[1] * t.size()[2] * t.size()[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1750087938651,
     "user": {
      "displayName": "Jo LImonadnui",
      "userId": "13339600552952595370"
     },
     "user_tz": -180
    },
    "id": "qgMQdmlUn-Ok"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(channels),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(channels, channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.layers(x)\n",
    "        return x + residual\n",
    "\n",
    "\n",
    "class UpsampleBLock(nn.Module):\n",
    "    def __init__(self, in_channels, up_scale=2):\n",
    "        super(UpsampleBLock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, in_channels * up_scale ** 2, kernel_size=3, padding=1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(up_scale)\n",
    "        self.prelu = nn.PReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.pixel_shuffle(x)\n",
    "        x = self.prelu(x)\n",
    "        return x\n",
    "\n",
    "class Conv_Dis(nn.Module):\n",
    "  def __init__(self, in_size:int, out_size:int):\n",
    "    super(Conv_Dis, self).__init__()\n",
    "    self.layers = nn.ModuleList([\n",
    "        nn.Conv2d(in_size, out_size, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(out_size),\n",
    "        nn.LeakyReLU(0.2),\n",
    "    ])\n",
    "    def forward(self, x):\n",
    "      for layer in self.layers:\n",
    "        x = layer(x)\n",
    "      return x\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, scale_factor:int=2, num_hidden_residuals:int=5):\n",
    "        upsample_block_num = int(math.log(scale_factor, 2))\n",
    "\n",
    "        super(Generator, self).__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=9, padding=4),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        self.hidden_residuals = nn.Sequential(*[ResidualBlock(64) for _ in range(num_hidden_residuals)])\n",
    "        self.block7 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        block8 = [UpsampleBLock(64, 2) for _ in range(upsample_block_num)]\n",
    "        block8.append(nn.Conv2d(64, 3, kernel_size=9, padding=4))\n",
    "        self.block8 = nn.Sequential(*block8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        block1 = self.block1(x)\n",
    "        block_n = self.hidden_residuals(block1)\n",
    "        block_n1 = self.block8(block1 + block_n)\n",
    "\n",
    "        return (torch.tanh(block_n1) + 1) / 2\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_size:int=3, out_size:int=1, hidden_size:int=64, num_hidden_layers=7):\n",
    "        super(Discriminator, self).__init__()\n",
    "        h = hidden_size\n",
    "        self.start_net = nn.Sequential(\n",
    "            nn.Conv2d(in_size, h, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for _ in range(num_hidden_layers):\n",
    "            h_next = h if _%2==0 else h * 2\n",
    "            self.hidden_layers.append(Conv_Dis(h, h_next))\n",
    "            h = h_next\n",
    "\n",
    "        self.end_net = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(h, h*2, kernel_size=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(h*2, out_size, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.start_net(x)\n",
    "        for layer in self.hidden_layers:\n",
    "          x = layer(x)\n",
    "        return torch.sigmoid(self.end_net(x).view(batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 160888,
     "status": "ok",
     "timestamp": 1750088428763,
     "user": {
      "displayName": "Jo LImonadnui",
      "userId": "13339600552952595370"
     },
     "user_tz": -180
    },
    "id": "uhHsNz9MxGY9",
    "outputId": "84e07969-bfb7-40f8-dd3c-b8cfa571a721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-06-16 15:37:45--  http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_wild.zip\n",
      "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.178, 2001:67c:10ec:36c2::178\n",
      "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_wild.zip [following]\n",
      "--2025-06-16 15:37:46--  https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_wild.zip\n",
      "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1079873385 (1.0G) [application/zip]\n",
      "Saving to: ‘DIV2K_train_LR_wild.zip’\n",
      "\n",
      "DIV2K_train_LR_wild 100%[===================>]   1.00G  28.4MB/s    in 38s     \n",
      "\n",
      "2025-06-16 15:38:25 (26.8 MB/s) - ‘DIV2K_train_LR_wild.zip’ saved [1079873385/1079873385]\n",
      "\n",
      "--2025-06-16 15:38:25--  http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
      "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.178, 2001:67c:10ec:36c2::178\n",
      "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip [following]\n",
      "--2025-06-16 15:38:25--  https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
      "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3530603713 (3.3G) [application/zip]\n",
      "Saving to: ‘DIV2K_train_HR.zip’\n",
      "\n",
      "DIV2K_train_HR.zip  100%[===================>]   3.29G  28.6MB/s    in 2m 1s   \n",
      "\n",
      "2025-06-16 15:40:26 (27.9 MB/s) - ‘DIV2K_train_HR.zip’ saved [3530603713/3530603713]\n",
      "\n",
      "Archive:  DIV2K_train_LR_wild.zip\n",
      "caution: filename not matched:  DIV2K_train_HR.zip\n"
     ]
    }
   ],
   "source": [
    "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_wild.zip\n",
    "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
    "!unzip DIV2K_train_LR_wild.zip -d datasets/\n",
    "!unzip DIV2K_train_HR.zip -d datasets/\n",
    "!rm -rf *.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 216,
     "status": "ok",
     "timestamp": 1750089906807,
     "user": {
      "displayName": "Jo LImonadnui",
      "userId": "13339600552952595370"
     },
     "user_tz": -180
    },
    "id": "oDsah_KOe8Jj",
    "outputId": "31cfc6ff-1128-4ecb-afd0-84ac3e742602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "3200\n"
     ]
    }
   ],
   "source": [
    "!ls -l datasets/DIV2K_train_HR | grep png -c\n",
    "!ls -l datasets/DIV2K_train_LR_wild | grep png -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RdhPpMYcvrQq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOGqOQpzAJ+SgTw/bI3Xx0M",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
