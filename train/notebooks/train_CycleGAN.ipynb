{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOWwXiRNjGUN"
   },
   "source": [
    "##Train notebook\n",
    "Ниже представлен цикл обучения `CycleGan` на `GoogleColabortory`. Если хотите использовать его для обучения - следуйте комментариям ниже. И затем нажмите `ctrl+f9`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1751722444680,
     "user": {
      "displayName": "Finger",
      "userId": "02278045276800783111"
     },
     "user_tz": -180
    },
    "id": "6wzLK2nvPZwv"
   },
   "outputs": [],
   "source": [
    "# в FILE укажите, какой датасет будете использовать\n",
    "# на выбор: apple2orange, summer2winter_yosemite, horse2zebra, monet2photo,\n",
    "# cezanne2photo, ukiyoe2photo, vangogh2photo, maps, cityscapes, facades,\n",
    "# iphone2dslr_flower, ae_photos\n",
    "\n",
    "FILE = \"summer2winter_yosemite\"\n",
    "\n",
    "# если в FILE используете датасет, отличный от тех, что ниже, то не забудьте его добавить\n",
    "if FILE == \"summer2winter_yosemite\": prefix = \"sum2win\"\n",
    "\n",
    "# в drive_path укажите путь к директории с проектм, чтобы все данные сохранялись там\n",
    "drive_path = \"/content/drive/MyDrive/TelegramStyleBot/\"\n",
    "path_to_dicts = drive_path + \"st_dicts/\"\n",
    "path_to_conf = drive_path + f\"train/configs/{prefix}_losses.json\"\n",
    "\n",
    "# будете ли вы сохранять и использовать данные с диска\n",
    "use_drive = True\n",
    "\n",
    "# инициализировать ли веса модели заново, если нет,\n",
    "# то они будут загружены из словарей состояния\n",
    "init_model = False\n",
    "\n",
    "# иногда дискриминатор может сталть слишком сильным,\n",
    "# поэтому можно обновлять его веса только каждые n эпох обучения\n",
    "skip_disc = False; skip_step = 3\n",
    "\n",
    "n_epochs = 2; batch_size = 2; dataroot = f\"datasets/{FILE}/\";\n",
    "lr = 1e-4; size = 256; input_nc = 3; output_nc = 3;\n",
    "id_loss_coef = 0.3; gan_loss_coef = 1.5; cycle_loss_coef = 10\n",
    "gen_lr_coef = 1; disc_lr_coef = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35098,
     "status": "ok",
     "timestamp": 1751722479789,
     "user": {
      "displayName": "Finger",
      "userId": "02278045276800783111"
     },
     "user_tz": -180
    },
    "id": "yLBcGr_cwTyb",
    "outputId": "e545d671-07c5-443c-d7e6-c06164ab5e34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import time\n",
    "\n",
    "if use_drive:\n",
    "  for _ in range(2):\n",
    "    try:\n",
    "      drive.mount('/content/drive')\n",
    "      break\n",
    "    except:\n",
    "      time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 99191,
     "status": "ok",
     "timestamp": 1751722578881,
     "user": {
      "displayName": "Finger",
      "userId": "02278045276800783111"
     },
     "user_tz": -180
    },
    "id": "DIp7cfmNQ93M",
    "outputId": "4ef9031b-baf7-4557-fd97-47167e7287f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.7.4-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.0.2)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (24.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.6.0+cu124)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.18.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->torchmetrics)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->torchmetrics)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->torchmetrics)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->torchmetrics)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->torchmetrics)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->torchmetrics)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
      "Downloading torchmetrics-1.7.4-py3-none-any.whl (963 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchmetrics-1.7.4\n",
      "Collecting ujson\n",
      "  Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ujson\n",
      "Successfully installed ujson-5.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics && pip install ujson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19145,
     "status": "ok",
     "timestamp": 1751722598029,
     "user": {
      "displayName": "Finger",
      "userId": "02278045276800783111"
     },
     "user_tz": -180
    },
    "id": "Yy4k7O_l7Tfb",
    "outputId": "1ef95f75-9fd7-423b-aa5d-2c42e6605845"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.models import vgg16\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics.image import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "psnr_metric = PeakSignalNoiseRatio().to(device)\n",
    "ssim_metric = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import random\n",
    "import os\n",
    "import ujson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1751722598088,
     "user": {
      "displayName": "Finger",
      "userId": "02278045276800783111"
     },
     "user_tz": -180
    },
    "id": "pGoNncy_hhtU"
   },
   "outputs": [],
   "source": [
    "!rm -rf ./datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34981,
     "status": "ok",
     "timestamp": 1751722633080,
     "user": {
      "displayName": "Finger",
      "userId": "02278045276800783111"
     },
     "user_tz": -180
    },
    "id": "Ptjifsk0cfGv",
    "outputId": "6cb76491-30b6-4436-b729-c082815f6ba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: timestamping does nothing in combination with -O. See the manual\n",
      "for details.\n",
      "\n",
      "--2025-07-05 13:36:37--  http://efrosgans.eecs.berkeley.edu/cyclegan/datasets/summer2winter_yosemite.zip\n",
      "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.244.190\n",
      "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.244.190|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 132640856 (126M) [application/zip]\n",
      "Saving to: ‘./datasets/summer2winter_yosemite.zip’\n",
      "\n",
      "./datasets/summer2w 100%[===================>] 126.50M  3.34MB/s    in 32s     \n",
      "\n",
      "2025-07-05 13:37:09 (3.91 MB/s) - ‘./datasets/summer2winter_yosemite.zip’ saved [132640856/132640856]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "URL = f\"http://efrosgans.eecs.berkeley.edu/cyclegan/datasets/{FILE}.zip\"\n",
    "ZIP_FILE = f\"./datasets/{FILE}.zip\"\n",
    "TARGET_DIR = f\"./datasets/{FILE}\"\n",
    "\n",
    "!mkdir -p ./datasets\n",
    "\n",
    "!wget -N \"{URL}\" -O \"{ZIP_FILE}\"\n",
    "\n",
    "!unzip -q \"{ZIP_FILE}\" -d ./datasets/\n",
    "!rm \"{ZIP_FILE}\"\n",
    "\n",
    "!mkdir -p \"{TARGET_DIR}/train/A\" \"{TARGET_DIR}/train/B\" \"{TARGET_DIR}/test/A\" \"{TARGET_DIR}/test/B\"\n",
    "\n",
    "!mv \"{TARGET_DIR}/trainA/\"* \"{TARGET_DIR}/train/A/\"\n",
    "!mv \"{TARGET_DIR}/trainB/\"* \"{TARGET_DIR}/train/B/\"\n",
    "!mv \"{TARGET_DIR}/testA/\"* \"{TARGET_DIR}/test/A/\"\n",
    "!mv \"{TARGET_DIR}/testB/\"* \"{TARGET_DIR}/test/B/\"\n",
    "\n",
    "!rm -rf \"{TARGET_DIR}/trainA\"\n",
    "!rm -rf \"{TARGET_DIR}/trainB\"\n",
    "!rm -rf \"{TARGET_DIR}/testA\"\n",
    "!rm -rf \"{TARGET_DIR}/testB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 98,
     "status": "ok",
     "timestamp": 1751722633192,
     "user": {
      "displayName": "Finger",
      "userId": "02278045276800783111"
     },
     "user_tz": -180
    },
    "id": "351NdiCE18W8",
    "outputId": "54d7c1c8-9e0a-4d56-dcdc-9708e72c7bdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12\n",
      "drwxr-xr-x 3 root root 4096 Jul  5 13:37 datasets\n",
      "drwx------ 5 root root 4096 Jul  5 13:34 drive\n",
      "drwxr-xr-x 1 root root 4096 Jul  1 21:04 sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 128,
     "status": "ok",
     "timestamp": 1751722633326,
     "user": {
      "displayName": "Finger",
      "userId": "02278045276800783111"
     },
     "user_tz": -180
    },
    "id": "H1B6M-zgKl1S"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        conv_block = [  nn.Conv2d(in_features, in_features, 3, padding=1, padding_mode='reflect'),\n",
    "                        nn.InstanceNorm2d(in_features),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Conv2d(in_features, in_features, 3, padding=1, padding_mode='reflect'),\n",
    "                        nn.InstanceNorm2d(in_features),\n",
    "                        nn.ReLU(inplace=True) ]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, device, input_nc, output_nc, n_du_samples=1, n_residual_blocks=2, hidden_size=96):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        model = [   nn.Conv2d(input_nc, hidden_size, 7, padding=3, padding_mode='reflect'),\n",
    "                    nn.InstanceNorm2d(hidden_size),\n",
    "                    nn.ReLU(inplace=True) ]\n",
    "\n",
    "        in_features = hidden_size\n",
    "        out_features = in_features*2\n",
    "        for _ in range(n_du_samples):\n",
    "            model += [  nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
    "                        nn.InstanceNorm2d(out_features),\n",
    "                        nn.ReLU(inplace=True) ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features*2\n",
    "\n",
    "        for _ in range(n_residual_blocks):\n",
    "            model += [ResidualBlock(in_features)]\n",
    "\n",
    "        out_features = in_features//2\n",
    "        for idx in range(n_du_samples):\n",
    "            upsample_block = [\n",
    "                nn.Conv2d(in_features, out_features * 4, kernel_size=3, padding=1, padding_mode='reflect'),\n",
    "                nn.PixelShuffle(2),\n",
    "                # nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "\n",
    "            model += upsample_block\n",
    "            in_features = out_features\n",
    "            out_features = in_features // 2\n",
    "\n",
    "        model += [  nn.Conv2d(hidden_size, output_nc, 7, padding=3, padding_mode='reflect'),\n",
    "                    nn.Tanh() ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "        self.model.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).to(self.device)\n",
    "\n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "            nn.init.normal_(m.weight, 0, 0.02)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, device, input_nc, hidden_n:int=2, hidden_size:int=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.device = device\n",
    "        h = hidden_size\n",
    "\n",
    "        model = [   nn.Conv2d(input_nc, h, 4, stride=2, padding=1),\n",
    "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
    "\n",
    "        for _ in range(hidden_n):\n",
    "            h_next = h*2\n",
    "            model += [\n",
    "                    nn.Conv2d(h, h_next, 4, stride=2, padding=1),\n",
    "                    nn.InstanceNorm2d(h_next),\n",
    "                    nn.LeakyReLU(0.2, inplace=True)\n",
    "                ]\n",
    "            h = h_next\n",
    "\n",
    "        model += [nn.Conv2d(h, 1, 4, padding=1)]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "        self.model.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x =  self.model(x)\n",
    "        return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1).to(self.device)\n",
    "\n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "            nn.init.normal_(m.weight, 0, 0.02)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1751722633335,
     "user": {
      "displayName": "Finger",
      "userId": "02278045276800783111"
     },
     "user_tz": -180
    },
    "id": "rbVDfbkwNPbY"
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, transforms_=None, unaligned=False, mode='train'):\n",
    "        self.transform = transforms.Compose(transforms_)\n",
    "        self.unaligned = unaligned\n",
    "\n",
    "        self.files_A = sorted(glob.glob(os.path.join(root, mode, 'A') + '/*.*'))\n",
    "        self.files_B = sorted(glob.glob(os.path.join(root, mode, 'B') + '/*.*'))\n",
    "\n",
    "        if len(self.files_A) == 0:\n",
    "            raise RuntimeError(f\"No files found in {os.path.exists(os.path.join(root, mode, 'A'))}\")\n",
    "        if len(self.files_B) == 0:\n",
    "            raise RuntimeError(f\"No files found in {os.path.exists(os.path.join(root, mode, 'B'))}\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item_A = self.transform(Image.open(self.files_A[index % len(self.files_A)]).convert('RGB'))\n",
    "\n",
    "        if self.unaligned:\n",
    "            item_B = self.transform(Image.open(self.files_B[random.randint(0, len(self.files_B) - 1)]).convert('RGB'))\n",
    "        else:\n",
    "            item_B = self.transform(Image.open(self.files_B[index % len(self.files_B)]).convert('RGB'))\n",
    "\n",
    "        return {'A': item_A, 'B': item_B}\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.files_A), len(self.files_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1751722633341,
     "user": {
      "displayName": "Finger",
      "userId": "02278045276800783111"
     },
     "user_tz": -180
    },
    "id": "ZVPE2VQORNxu"
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size=50):\n",
    "        self.max_size = max_size\n",
    "        self.buffer = []  # [1, C, H, W]\n",
    "\n",
    "    def push_and_pop(self, data: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Принимает/возвращает тензоры в формате [N, C, H, W]\"\"\"\n",
    "        outputs = []\n",
    "\n",
    "        for image in data:\n",
    "            image = image.unsqueeze(0)  # [C,H,W] -> [1,C,H,W]\n",
    "\n",
    "            if len(self.buffer) < self.max_size:\n",
    "                self.buffer.append(image)\n",
    "                outputs.append(image)\n",
    "            else:\n",
    "                if random.random() > 0.5:  # 50% возвращаем из буфера\n",
    "                    idx = random.randint(0, self.max_size - 1)\n",
    "                    outputs.append(self.buffer[idx].clone())\n",
    "                    self.buffer[idx] = image  # Заменяем старый элемент\n",
    "                else:\n",
    "                    outputs.append(image)  # Возвращаем новый элемент\n",
    "\n",
    "        # Все в один тензор [K, C, H, W]\n",
    "        return torch.cat(outputs, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1751722633348,
     "user": {
      "displayName": "Finger",
      "userId": "02278045276800783111"
     },
     "user_tz": -180
    },
    "id": "i8z_VwM4_Cqh"
   },
   "outputs": [],
   "source": [
    "def load_or_create_config(path, sub_conf):\n",
    "    try:\n",
    "        with open(path, \"r\") as file:\n",
    "            return ujson.load(file)\n",
    "    except:\n",
    "        with open(path, \"w\") as file:\n",
    "            ujson.dump(sub_conf, file)\n",
    "        return sub_conf\n",
    "\n",
    "def load_to_conf(path_to_conf:str, sub_conf:dict, temp_list:list):\n",
    "  target = load_or_create_config(path_to_conf, sub_conf)\n",
    "\n",
    "  for _ in range(2):\n",
    "    try:\n",
    "      for i, key in enumerate(sub_conf):\n",
    "          target[key].append(temp_list[i])\n",
    "      break\n",
    "    except:\n",
    "      target.update(sub_conf)\n",
    "\n",
    "\n",
    "  with open(path_to_conf, \"w\") as file:\n",
    "      ujson.dump(target, file)\n",
    "\n",
    "# prefix = \"net\"\n",
    "# path_to_conf_dir = \"/content/confs/\"\n",
    "\n",
    "# path_to_conf = path_to_conf_dir + prefix + \"_conf.json\"\n",
    "\n",
    "\n",
    "# sub_conf = {\"1\": [], \"2\": []}\n",
    "\n",
    "# first = 1\n",
    "# second = 2\n",
    "# temp_list = [first, second]\n",
    "\n",
    "# load_to_conf(path_to_conf, sub_conf, temp_list)\n",
    "\n",
    "\n",
    "# with open(path_to_conf, \"r\") as file:\n",
    "#     main_conf = ujson.load(file)\n",
    "#     print(main_conf)\n",
    "\n",
    "def compute_metrics(real, generated, recovered):\n",
    "    with torch.no_grad():\n",
    "        real_01 = (real + 1) / 2\n",
    "        gen_01 = (generated + 1) / 2\n",
    "        rec_01 = (recovered + 1) / 2\n",
    "\n",
    "        psnr_val = psnr_metric(gen_01, real_01)\n",
    "        ssim_val = ssim_metric(gen_01, real_01)\n",
    "        cycle_psnr = psnr_metric(rec_01, real_01)\n",
    "        cycle_ssim = ssim_metric(rec_01, real_01)\n",
    "\n",
    "    return psnr_val.item(), ssim_val.item(), cycle_psnr.item(), cycle_ssim.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 154,
     "status": "ok",
     "timestamp": 1751726330955,
     "user": {
      "displayName": "Finger",
      "userId": "02278045276800783111"
     },
     "user_tz": -180
    },
    "id": "IzWGE1P5lfgz",
    "outputId": "2bc46e6a-d7b8-40d4-f7a5-fd92d7f63603"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n",
      "    (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ResidualBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "        (1): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "        (4): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (7): ResidualBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "        (1): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "        (4): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (8): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "    (9): PixelShuffle(upscale_factor=2)\n",
      "    (10): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(96, 3, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n",
      "Модель sum2win_netG_A2B.pth успешно загружена\n",
      "Модель sum2win_netG_B2A.pth успешно загружена\n",
      "Модель sum2win_netD_A.pth успешно загружена\n",
      "Модель sum2win_netD_B.pth успешно загружена\n"
     ]
    }
   ],
   "source": [
    "netG_A2B = Generator(device, input_nc, output_nc).to(device)\n",
    "print(netG_A2B)\n",
    "netG_B2A = Generator(device, output_nc, input_nc).to(device)\n",
    "\n",
    "netD_A = Discriminator(device, input_nc).to(device)\n",
    "netD_B = Discriminator(device, output_nc).to(device)\n",
    "\n",
    "def load_model(model, filename):\n",
    "    model_path = path_to_dicts + filename\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    print(f\"Модель {filename} успешно загружена\")\n",
    "\n",
    "def save_model(model, path_to_dicts):\n",
    "    model.to('cpu')\n",
    "    torch.save(model.state_dict(), path_to_dicts)\n",
    "    model.to(device)\n",
    "\n",
    "if not init_model:\n",
    "  load_model(netG_A2B, f'{prefix}_netG_A2B.pth')\n",
    "  load_model(netG_B2A, f'{prefix}_netG_B2A.pth')\n",
    "  load_model(netD_A, f'{prefix}_netD_A.pth')\n",
    "  load_model(netD_B, f'{prefix}_netD_B.pth')\n",
    "\n",
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_cycle = torch.nn.L1Loss()\n",
    "criterion_identity = torch.nn.L1Loss()\n",
    "\n",
    "optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()),\n",
    "                                lr=(lr*gen_lr_coef), betas=(0.5, 0.999))\n",
    "\n",
    "optimizer_D_A = torch.optim.Adam(netD_A.parameters(), lr=(lr*disc_lr_coef), betas=(0.5, 0.999))\n",
    "optimizer_D_B = torch.optim.Adam(netD_B.parameters(), lr=(lr*disc_lr_coef), betas=(0.5, 0.999))\n",
    "\n",
    "transforms_ = [ transforms.Resize(int(size*1.12), Image.BICUBIC),\n",
    "                transforms.RandomCrop(size),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
    "dataloader = DataLoader(ImageDataset(dataroot, transforms_=transforms_, unaligned=True),\n",
    "                        batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zNPFGd37twO_"
   },
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor if device == 'cuda' else torch.Tensor\n",
    "input_A = Tensor(batch_size, input_nc, size, size)\n",
    "input_B = Tensor(batch_size, output_nc, size, size)\n",
    "target_real = torch.ones(batch_size, 1, device=device, requires_grad=False)\n",
    "target_fake = torch.zeros(batch_size, 1, device=device, requires_grad=False)\n",
    "\n",
    "fake_A_buffer = ReplayBuffer()\n",
    "fake_B_buffer = ReplayBuffer()\n",
    "\n",
    "losses_dict = {\n",
    "    'GA_Loss': [],\n",
    "    'GB_Loss': [],\n",
    "    'DA_Loss': [],\n",
    "    'DB_Loss': [],\n",
    "    'PSNR_avg': [],\n",
    "    'SSIM_avg': [],\n",
    "    'Cycle_PSNR_avg': [],\n",
    "    'Cycle_SSIM_avg': [],\n",
    "}\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  gen_loss = 0\n",
    "  ga_loss = 0\n",
    "  gb_loss = 0\n",
    "  da_loss = 0\n",
    "  db_loss = 0\n",
    "\n",
    "  psnr_total = 0.0\n",
    "  ssim_total = 0.0\n",
    "  cycle_psnr_total = 0.0\n",
    "  cycle_ssim_total = 0.0\n",
    "  metric_count = 0\n",
    "\n",
    "  for i, batch in enumerate(dataloader):\n",
    "\n",
    "    real_A = batch['A'].to(device, dtype=torch.float32)\n",
    "    real_B = batch['B'].to(device, dtype=torch.float32)\n",
    "\n",
    "    ###### Gens A2B & B2A ######\n",
    "    optimizer_G.zero_grad()\n",
    "\n",
    "    # Identity loss\n",
    "    same_B = netG_A2B(real_B)\n",
    "    loss_identity_B = criterion_identity(same_B, real_B)*id_loss_coef\n",
    "\n",
    "    same_A = netG_B2A(real_A)\n",
    "    loss_identity_A = criterion_identity(same_A, real_A)*id_loss_coef\n",
    "\n",
    "    # GAN loss\n",
    "    fake_B = netG_A2B(real_A)\n",
    "    pred_fake = netD_B(fake_B) #(1, 1)\n",
    "    loss_GAN_A2B = criterion_GAN(pred_fake, target_real)*gan_loss_coef\n",
    "\n",
    "    fake_A = netG_B2A(real_B)\n",
    "    pred_fake = netD_A(fake_A)\n",
    "    loss_GAN_B2A = criterion_GAN(pred_fake, target_real)*gan_loss_coef\n",
    "\n",
    "    imgs = {\n",
    "    'real_A': real_A, 'fake_B': fake_B, 'real_B': real_B, 'fake_A': fake_A\n",
    "    }\n",
    "\n",
    "    # Cycle loss\n",
    "    recovered_A = netG_B2A(fake_B)\n",
    "    loss_cycle_ABA = criterion_cycle(recovered_A, real_A)*cycle_loss_coef\n",
    "\n",
    "    recovered_B = netG_A2B(fake_A)\n",
    "    loss_cycle_BAB = criterion_cycle(recovered_B, real_B)*cycle_loss_coef\n",
    "\n",
    "    # Total loss\n",
    "    loss_G = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n",
    "    gen_loss += loss_G.item()\n",
    "    loss_G.backward()\n",
    "\n",
    "    ga_loss += (loss_identity_B + loss_GAN_A2B).item()\n",
    "    gb_loss += (loss_identity_A + loss_GAN_B2A).item()\n",
    "\n",
    "    optimizer_G.step()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ###### Disc A ######\n",
    "\n",
    "    # Real loss\n",
    "    pred_real = netD_A(real_A)\n",
    "    loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "\n",
    "    # Fake loss\n",
    "    fake_A = fake_A_buffer.push_and_pop(fake_A)\n",
    "    pred_fake = netD_A(fake_A.detach())\n",
    "    loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "    # Total loss\n",
    "    loss_D_A = (loss_D_real + loss_D_fake)*0.5\n",
    "    da_loss += loss_D_A.item()\n",
    "\n",
    "    if ((epoch+1) % skip_step == 0) or (not skip_disc):\n",
    "      optimizer_D_A.zero_grad()\n",
    "      loss_D_A.backward()\n",
    "      optimizer_D_A.step()\n",
    "      torch.cuda.empty_cache()\n",
    "\n",
    "    ###### Disc B ######\n",
    "\n",
    "    # Real loss\n",
    "    pred_real = netD_B(real_B)\n",
    "    loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "\n",
    "    # Fake loss\n",
    "    fake_B = fake_B_buffer.push_and_pop(fake_B)\n",
    "    pred_fake = netD_B(fake_B.detach())\n",
    "    loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "    # Total loss\n",
    "    loss_D_B = (loss_D_real + loss_D_fake)*0.5\n",
    "    db_loss += loss_D_B.item()\n",
    "\n",
    "    if ((epoch+1) % skip_step == 0) or (not skip_disc):\n",
    "      optimizer_D_B.zero_grad()\n",
    "      loss_D_B.backward()\n",
    "      optimizer_D_B.step()\n",
    "      torch.cuda.empty_cache()\n",
    "\n",
    "    if i % 10 == 0:\n",
    "            psnr_a, ssim_a, cycle_psnr_a, cycle_ssim_a = compute_metrics(real_A, fake_B, recovered_A)\n",
    "\n",
    "            psnr_b, ssim_b, cycle_psnr_b, cycle_ssim_b = compute_metrics(real_B, fake_A, recovered_B)\n",
    "\n",
    "            psnr_total += (psnr_a + psnr_b) / 2\n",
    "            ssim_total += (ssim_a + ssim_b) / 2\n",
    "            cycle_psnr_total += (cycle_psnr_a + cycle_psnr_b) / 2\n",
    "            cycle_ssim_total += (cycle_ssim_a + cycle_ssim_b) / 2\n",
    "            metric_count += 1\n",
    "\n",
    "  ga_loss /= len(dataloader)\n",
    "  gb_loss /= len(dataloader)\n",
    "  da_loss /= len(dataloader)\n",
    "  db_loss /= len(dataloader)\n",
    "\n",
    "  avg_psnr = psnr_total / metric_count if metric_count > 0 else 0\n",
    "  avg_ssim = ssim_total / metric_count if metric_count > 0 else 0\n",
    "  avg_cycle_psnr = cycle_psnr_total / metric_count if metric_count > 0 else 0\n",
    "  avg_cycle_ssim = cycle_ssim_total / metric_count if metric_count > 0 else 0\n",
    "\n",
    "  temp_list = [ga_loss, gb_loss, da_loss, db_loss, avg_psnr, avg_ssim, avg_cycle_psnr, avg_cycle_ssim]\n",
    "  load_to_conf(path_to_conf, losses_dict, temp_list)\n",
    "\n",
    "  if (epoch+1) % 2 == 0:\n",
    "      keys = ['real_A', 'fake_B', 'real_B', 'fake_A']\n",
    "\n",
    "      fig, axs = plt.subplots(2, 2, figsize=(12, 12))\n",
    "      axs = axs.flatten()\n",
    "\n",
    "      for j, key in enumerate(keys):\n",
    "        axs[j].imshow((imgs[key].cpu().detach()[0].clip(-1,1).permute(1, 2, 0) + 1) / 2)\n",
    "        axs[j].set_title(key)\n",
    "        axs[j].axis('off')\n",
    "\n",
    "      plt.show()\n",
    "\n",
    "      save_model(netG_A2B, f'{path_to_dicts}{prefix}_netG_A2B.pth')\n",
    "      save_model(netG_B2A, f'{path_to_dicts}{prefix}_netG_B2A.pth')\n",
    "      save_model(netD_A, f'{path_to_dicts}{prefix}_netD_A.pth')\n",
    "      save_model(netD_B, f'{path_to_dicts}{prefix}_netD_B.pth')\n",
    "\n",
    "with open(path_to_conf, \"r\") as file:\n",
    "  losses = ujson.load(file)\n",
    "  fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "  axs[0, 0].plot(losses['GA_Loss'], label='Gen_A')\n",
    "  axs[0, 0].plot(losses['GB_Loss'], label='Gen_B')\n",
    "  axs[0, 0].set_title(\"Generator Losses\")\n",
    "  axs[0, 0].legend()\n",
    "\n",
    "  axs[0, 1].plot(losses['DA_Loss'], label='Dis_A')\n",
    "  axs[0, 1].plot(losses['DB_Loss'], label='Dis_B')\n",
    "  axs[0, 1].set_title(\"Discriminator Losses\")\n",
    "  axs[0, 1].legend()\n",
    "\n",
    "  axs[1, 0].plot(losses['PSNR_avg'], label='PSNR')\n",
    "  axs[1, 0].plot(losses['Cycle_PSNR_avg'], label='Cycle_PSNR')\n",
    "  axs[1, 0].set_title(\"PSNR Metrics\")\n",
    "  axs[1, 0].legend()\n",
    "\n",
    "  axs[1, 1].plot(losses['SSIM_avg'], label='SSIM')\n",
    "  axs[1, 1].plot(losses['Cycle_SSIM_avg'], label='Cycle_SSIM')\n",
    "  axs[1, 1].set_title(\"SSIM Metric\")\n",
    "  axs[1, 1].legend()\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
